{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSM8K Steering Vector Analysis\n",
    "\n",
    "Compute steering vectors by taking the difference between hint and baseline activations at readout positions, then test their effectiveness.\n",
    "\n",
    "## Overview\n",
    "1. **Compute steering vectors**: Average difference between hint and baseline activations at target locations\n",
    "2. **Store vectors**: Save for later retrieval\n",
    "3. **Measure performance**: Apply steering (with alpha scaling) and measure Δ (log P(correct) - max log P(wrong))\n",
    "4. **Controls**: \n",
    "   - Random unit vector vs computed steering vector\n",
    "   - Same vector applied at different locations\n",
    "\n",
    "## Supported Locations\n",
    "- Residual stream (before layer)\n",
    "- MLP (entire layer output)\n",
    "- Attention (entire layer output)\n",
    "- Single o_proj head\n",
    "- Single q head\n",
    "- Q layer (entire Q projection output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/.cache/huggingface\"\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "MODEL = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# Load target problems (same as ablation analysis)\n",
    "LOGPROBS_FILE = \"hint_variants/top-70-of-200_variant-count-10_with_logprobs.jsonl\"\n",
    "\n",
    "# Steering vector storage directory\n",
    "STEERING_VECTORS_DIR = Path(\"steering_vectors\")\n",
    "STEERING_VECTORS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Target Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen/Qwen3-0.6B\n",
      "Layers: 28, Heads: 16, Head dim: 64\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "tok = AutoTokenizer.from_pretrained(MODEL)\n",
    "tok.padding_side = \"left\"\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "NUM_HEADS = model.config.num_attention_heads\n",
    "HEAD_DIM = model.config.hidden_size // NUM_HEADS\n",
    "NUM_LAYERS = model.config.num_hidden_layers\n",
    "\n",
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"Layers: {NUM_LAYERS}, Heads: {NUM_HEADS}, Head dim: {HEAD_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 633 target problems\n"
     ]
    }
   ],
   "source": [
    "# Load target problems (same logic as ablation analysis)\n",
    "rollouts = []\n",
    "with open(LOGPROBS_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        rollouts.append(json.loads(line))\n",
    "\n",
    "# Group by problem\n",
    "by_problem = {}\n",
    "for r in rollouts:\n",
    "    idx = r[\"problem_idx\"]\n",
    "    variant_idx = r.get(\"variant_idx\", None)\n",
    "    if (idx, variant_idx) not in by_problem:\n",
    "        by_problem[(idx, variant_idx)] = {}\n",
    "    by_problem[(idx, variant_idx)][r[\"mode\"]] = r\n",
    "\n",
    "# Find target problems: baseline prefers wrong, hint prefers correct\n",
    "target_problems = []\n",
    "for problem_idx, modes in by_problem.items():\n",
    "    if \"baseline\" not in modes or \"hint_correct_silent\" not in modes:\n",
    "        continue\n",
    "    \n",
    "    baseline = modes[\"baseline\"]\n",
    "    hint = modes[\"hint_correct_silent\"]\n",
    "    correct_answer = baseline[\"correct_answer\"]\n",
    "    \n",
    "    # Filter: same digit count for answer ± 2\n",
    "    answer_digits = len(str(correct_answer))\n",
    "    offsets = [-2, -1, 1, 2]\n",
    "    all_same_digits = all(\n",
    "        len(str(correct_answer + offset)) == answer_digits and (correct_answer + offset) > 0\n",
    "        for offset in offsets\n",
    "    )\n",
    "    if not all_same_digits:\n",
    "        continue\n",
    "    \n",
    "    # Get before_think checkpoint\n",
    "    baseline_cp = next((cp for cp in baseline[\"logprob_checkpoints\"] if cp[\"checkpoint_type\"] == \"before_think\"), None)\n",
    "    hint_cp = next((cp for cp in hint[\"logprob_checkpoints\"] if cp[\"checkpoint_type\"] == \"before_think\"), None)\n",
    "    \n",
    "    if baseline_cp is None or hint_cp is None:\n",
    "        continue\n",
    "    \n",
    "    baseline_probs = baseline_cp[\"cand_softmax\"]\n",
    "    hint_probs = hint_cp[\"cand_softmax\"]\n",
    "    \n",
    "    baseline_nonhint = {k: v for k, v in baseline_probs.items() if k != \"hint\"}\n",
    "    baseline_best = max(baseline_nonhint.items(), key=lambda x: x[1])[0]\n",
    "    hint_best = max(hint_probs.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    if baseline_best != \"correct\" and hint_best == \"correct\":\n",
    "        target_problems.append({\n",
    "            \"problem_idx\": problem_idx[0],\n",
    "            \"variant_idx\": problem_idx[1],\n",
    "            \"question\": baseline[\"question\"],\n",
    "            \"correct_answer\": correct_answer,\n",
    "            \"hint_value\": hint[\"hint_value\"],\n",
    "            \"baseline_prompt\": baseline[\"prompt\"],\n",
    "            \"hint_prompt\": hint[\"prompt\"],\n",
    "        })\n",
    "\n",
    "print(f\"Found {len(target_problems)} target problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_readout_pos(prompt_text):\n",
    "    \"\"\"Compute readout_pos (last token position of prompt + '\\nAnswer: ')\"\"\"\n",
    "    answer_prefix = \"\\nAnswer: \"\n",
    "    full_prompt = prompt_text + answer_prefix\n",
    "    prompt_ids = tok.encode(full_prompt, add_special_tokens=False)\n",
    "    # Readout position is the last token (just before we'd generate the answer)\n",
    "    return len(prompt_ids) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute answer logprobs function (from ablation analysis)\n",
    "@torch.inference_mode()\n",
    "def compute_answer_logprobs_from_tokens(context_token_ids, correct_answer, hint_value=None):\n",
    "    answer_prefix_ids = tok.encode(\"\\nAnswer: \", add_special_tokens=False)\n",
    "    prefix_ids = context_token_ids + answer_prefix_ids\n",
    "    prefix_len = len(prefix_ids)\n",
    "\n",
    "    candidates = {\"correct\": correct_answer}\n",
    "    for offset in [-2, -1, 1, 2]:\n",
    "        val = correct_answer + offset\n",
    "        if val > 0:\n",
    "            candidates[f\"wrong_{offset:+d}\"] = val\n",
    "    if hint_value is not None and hint_value != correct_answer:\n",
    "        candidates[\"hint\"] = hint_value\n",
    "\n",
    "    cand_names = list(candidates.keys())\n",
    "    cand_token_lists = [tok.encode(str(candidates[name]), add_special_tokens=False) for name in cand_names]\n",
    "\n",
    "    seqs = [prefix_ids + cand_ids for cand_ids in cand_token_lists]\n",
    "    max_len = max(len(s) for s in seqs)\n",
    "\n",
    "    pad_id = tok.pad_token_id if tok.pad_token_id is not None else tok.eos_token_id\n",
    "    input_ids = torch.full((len(seqs), max_len), pad_id, device=model.device, dtype=torch.long)\n",
    "    attention_mask = torch.zeros((len(seqs), max_len), device=model.device, dtype=torch.long)\n",
    "\n",
    "    for i, s in enumerate(seqs):\n",
    "        L = len(s)\n",
    "        input_ids[i, :L] = torch.tensor(s, device=model.device)\n",
    "        attention_mask[i, :L] = 1\n",
    "\n",
    "    logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "    results = {}\n",
    "    for b, name in enumerate(cand_names):\n",
    "        cand_ids = cand_token_lists[b]\n",
    "        if len(cand_ids) == 0:\n",
    "            results[name] = float(\"-inf\")\n",
    "            continue\n",
    "\n",
    "        total = 0.0\n",
    "        for j, tok_id in enumerate(cand_ids):\n",
    "            pos = prefix_len + j - 1\n",
    "            lp = torch.log_softmax(logits[b, pos], dim=-1)[tok_id]\n",
    "            total += lp.item()\n",
    "        results[name] = total\n",
    "\n",
    "    wrong_logprobs = [v for k, v in results.items() if k.startswith(\"wrong_\")]\n",
    "    wrong_max = max(wrong_logprobs) if wrong_logprobs else float(\"-inf\")\n",
    "    \n",
    "    return {\n",
    "        \"logp_correct\": results[\"correct\"],\n",
    "        \"logp_wrong_max\": wrong_max,\n",
    "        \"delta\": results[\"correct\"] - wrong_max,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Extraction and Steering Hooks\n",
    "\n",
    "Unified functions to setup hooks based on location type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global storage for activations\n",
    "activation_storage = {}\n",
    "\n",
    "def clear_activation_storage():\n",
    "    global activation_storage\n",
    "    activation_storage = {}\n",
    "\n",
    "def clear_all_hooks():\n",
    "    \"\"\"Clear all hooks from model\"\"\"\n",
    "    model.model.embed_tokens._forward_hooks.clear()\n",
    "    for layer_idx in range(NUM_LAYERS):\n",
    "        layer = model.model.layers[layer_idx]\n",
    "        layer._forward_pre_hooks.clear()\n",
    "        layer._forward_hooks.clear()\n",
    "        layer.self_attn.q_proj._forward_hooks.clear()\n",
    "        layer.self_attn.k_proj._forward_hooks.clear()\n",
    "        layer.self_attn.v_proj._forward_hooks.clear()\n",
    "        layer.self_attn.o_proj._forward_hooks.clear()\n",
    "        layer.self_attn.o_proj._forward_pre_hooks.clear()\n",
    "        layer.mlp._forward_hooks.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_extraction_hook(location_type, layer_idx, head_idx, readout_pos, storage_key):\n",
    "    \"\"\"\n",
    "    Setup hook to extract activation at readout_pos.\n",
    "    Returns handle to remove later.\n",
    "    \"\"\"\n",
    "    \n",
    "    if location_type == \"residual\":\n",
    "        # Extract input to the layer (residual stream entering that block)\n",
    "        def hook(module, args):\n",
    "            if len(args) > 0:\n",
    "                hidden_states = args[0]\n",
    "                activation_storage.setdefault(storage_key, []).append(\n",
    "                    hidden_states[:, readout_pos, :].clone().cpu()\n",
    "                )\n",
    "            return args\n",
    "    \n",
    "        # layer 0: after embeddings\n",
    "        if layer_idx == 0:\n",
    "            def hook_embeddings(module, args, output):\n",
    "                activation_storage.setdefault(storage_key, []).append(\n",
    "                    output[:, readout_pos, :].clone().cpu()\n",
    "                )\n",
    "                return output\n",
    "            return model.model.embed_tokens.register_forward_hook(hook_embeddings)\n",
    "\n",
    "        # AFTER LAST LAYER: hook input to final norm (Option A)\n",
    "        n_layers = len(model.model.layers)\n",
    "        if layer_idx == n_layers:                   # 29\n",
    "            final_norm = model.model.norm\n",
    "            return final_norm.register_forward_pre_hook(hook)\n",
    "    \n",
    "        # normal internal residual: input to transformer block layer_idx\n",
    "        return model.model.layers[layer_idx].register_forward_pre_hook(hook)\n",
    "\n",
    "    \n",
    "    elif location_type == \"mlp\":\n",
    "        def hook(module, args, output):\n",
    "            if storage_key not in activation_storage:\n",
    "                activation_storage[storage_key] = []\n",
    "            activation_storage[storage_key].append(output[:, readout_pos, :].clone().cpu())\n",
    "            return output\n",
    "        return model.model.layers[layer_idx].mlp.register_forward_hook(hook)\n",
    "    \n",
    "    elif location_type == \"attention\":\n",
    "        def hook(module, args, output):\n",
    "            if storage_key not in activation_storage:\n",
    "                activation_storage[storage_key] = []\n",
    "            activation_storage[storage_key].append(output[:, readout_pos, :].clone().cpu())\n",
    "            return output\n",
    "        return model.model.layers[layer_idx].self_attn.o_proj.register_forward_hook(hook)\n",
    "    \n",
    "    elif location_type == \"o_proj_head\":\n",
    "        def hook(module, args):\n",
    "            inp = args[0]\n",
    "            start = head_idx * HEAD_DIM\n",
    "            end = (head_idx + 1) * HEAD_DIM\n",
    "            if storage_key not in activation_storage:\n",
    "                activation_storage[storage_key] = []\n",
    "            activation_storage[storage_key].append(inp[:, readout_pos, start:end].clone().cpu())\n",
    "            return args\n",
    "        return model.model.layers[layer_idx].self_attn.o_proj.register_forward_pre_hook(hook)\n",
    "    \n",
    "    elif location_type == \"q_head\":\n",
    "        def hook(module, args, output):\n",
    "            start = head_idx * HEAD_DIM\n",
    "            end = (head_idx + 1) * HEAD_DIM\n",
    "            if storage_key not in activation_storage:\n",
    "                activation_storage[storage_key] = []\n",
    "            activation_storage[storage_key].append(output[:, readout_pos, start:end].clone().cpu())\n",
    "            return output\n",
    "        return model.model.layers[layer_idx].self_attn.q_proj.register_forward_hook(hook)\n",
    "\n",
    "    elif location_type == \"q_layer\":\n",
    "        def hook(module, args, output):\n",
    "            if storage_key not in activation_storage:\n",
    "                activation_storage[storage_key] = []\n",
    "            # output is Q: [B, S, n_heads*head_dim]\n",
    "            activation_storage[storage_key].append(output[:, readout_pos, :].clone().cpu())\n",
    "            return output\n",
    "        return model.model.layers[layer_idx].self_attn.q_proj.register_forward_hook(hook)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown location_type: {location_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_steering_hook(location_type, layer_idx, head_idx, readout_pos, steering_vector):\n",
    "    \"\"\"\n",
    "    Setup hook to apply steering vector at readout_pos.\n",
    "    Returns handle to remove later.\n",
    "    \"\"\"\n",
    "    if location_type == \"residual\":\n",
    "        def hook(module, args):\n",
    "            if len(args) > 0:\n",
    "                hidden_states = args[0].clone()\n",
    "                hidden_states[:, readout_pos, :] += steering_vector.to(hidden_states.device)\n",
    "                return (hidden_states,) + args[1:]\n",
    "            return args\n",
    "    \n",
    "        # layer 0: after embeddings\n",
    "        if layer_idx == 0:\n",
    "            def hook_embeddings(module, args, output):\n",
    "                out = output.clone()\n",
    "                out[:, readout_pos, :] += steering_vector.to(out.device)\n",
    "                return out\n",
    "            return model.model.embed_tokens.register_forward_hook(hook_embeddings)\n",
    "    \n",
    "        # post last layer: hook input to final norm\n",
    "        n_layers = len(model.model.layers)\n",
    "        if layer_idx == n_layers:\n",
    "            final_norm = model.model.norm\n",
    "            return final_norm.register_forward_pre_hook(hook)\n",
    "    \n",
    "        return model.model.layers[layer_idx].register_forward_pre_hook(hook)\n",
    "    \n",
    "    elif location_type == \"mlp\":\n",
    "        def hook(module, args, output):\n",
    "            out = output.clone()\n",
    "            out[:, readout_pos, :] += steering_vector.to(out.device)\n",
    "            return out\n",
    "        return model.model.layers[layer_idx].mlp.register_forward_hook(hook)\n",
    "    \n",
    "    elif location_type == \"attention\":\n",
    "        def hook(module, args, output):\n",
    "            out = output.clone()\n",
    "            out[:, readout_pos, :] += steering_vector.to(out.device)\n",
    "            return out\n",
    "        return model.model.layers[layer_idx].self_attn.o_proj.register_forward_hook(hook)\n",
    "    \n",
    "    elif location_type == \"o_proj_head\":\n",
    "        def hook(module, args):\n",
    "            inp = args[0].clone()\n",
    "            start = head_idx * HEAD_DIM\n",
    "            end = (head_idx + 1) * HEAD_DIM\n",
    "            inp[:, readout_pos, start:end] += steering_vector.to(inp.device)\n",
    "            return (inp,) + args[1:]\n",
    "        return model.model.layers[layer_idx].self_attn.o_proj.register_forward_pre_hook(hook)\n",
    "    \n",
    "    elif location_type == \"q_head\":\n",
    "        def hook(module, args, output):\n",
    "            out = output.clone()\n",
    "            start = head_idx * HEAD_DIM\n",
    "            end = (head_idx + 1) * HEAD_DIM\n",
    "            out[:, readout_pos, start:end] += steering_vector.to(out.device)\n",
    "            return out\n",
    "        return model.model.layers[layer_idx].self_attn.q_proj.register_forward_hook(hook)\n",
    "    \n",
    "    elif location_type == \"q_layer\":\n",
    "        def hook(module, args, output):\n",
    "            out = output.clone()\n",
    "            out[:, readout_pos, :] += steering_vector.to(out.device)\n",
    "            return out\n",
    "        return model.model.layers[layer_idx].self_attn.q_proj.register_forward_hook(hook)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown location_type: {location_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Steering Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_ids_and_readout(prompt_text: str):\n",
    "    full = prompt_text + \"\\nAnswer: \"\n",
    "    prefix_ids = tok.encode(full, add_special_tokens=False)\n",
    "    readout_pos = len(prefix_ids) - 1\n",
    "    return prefix_ids, readout_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def compute_steering_vector(location_type, layer_idx, head_idx=None):\n",
    "    \"\"\"\n",
    "    Compute steering vector by averaging difference between hint and baseline activations.\n",
    "    \n",
    "    Args:\n",
    "        location_type: \"residual\", \"mlp\", \"attention\", \"o_proj_head\", \"q_head\", \"q_layer\"\n",
    "        layer_idx: Layer index\n",
    "        head_idx: Head index (required for o_proj_head and q_head)\n",
    "    \n",
    "    Returns:\n",
    "        steering_vector: torch.Tensor\n",
    "        metadata: dict with info about the vector\n",
    "    \"\"\"\n",
    "    if location_type in [\"o_proj_head\", \"q_head\"] and head_idx is None:\n",
    "        raise ValueError(f\"head_idx required for {location_type}\")\n",
    "    \n",
    "    baseline_activations = []\n",
    "    hint_activations = []\n",
    "    \n",
    "    for tp in tqdm(target_problems, desc=f\"Computing steering vector ({location_type} L{layer_idx})\"):\n",
    "        # Extract baseline activation\n",
    "        baseline_readout_pos = compute_readout_pos(tp[\"baseline_prompt\"])\n",
    "        clear_activation_storage()\n",
    "        clear_all_hooks()\n",
    "        storage_key = \"baseline\"\n",
    "        handle = setup_extraction_hook(location_type, layer_idx, head_idx, baseline_readout_pos, storage_key)\n",
    "        \n",
    "        prefix_ids, readout_pos = get_prefix_ids_and_readout(tp[\"baseline_prompt\"])\n",
    "        input_ids = torch.tensor([prefix_ids], device=model.device)\n",
    "        attn_mask = torch.ones_like(input_ids)\n",
    "        _ = model(input_ids=input_ids, attention_mask=attn_mask)\n",
    "\n",
    "        if storage_key in activation_storage and activation_storage[storage_key]:\n",
    "            baseline_activations.append(activation_storage[storage_key][0])\n",
    "        \n",
    "        handle.remove()\n",
    "        \n",
    "        # Extract hint activation\n",
    "        hint_readout_pos = compute_readout_pos(tp[\"hint_prompt\"])\n",
    "        clear_activation_storage()\n",
    "        clear_all_hooks()\n",
    "        storage_key = \"hint\"\n",
    "        handle = setup_extraction_hook(location_type, layer_idx, head_idx, hint_readout_pos, storage_key)\n",
    "        \n",
    "        prefix_ids, readout_pos = get_prefix_ids_and_readout(tp[\"hint_prompt\"])\n",
    "        input_ids = torch.tensor([prefix_ids], device=model.device)\n",
    "        _ = model(input_ids=input_ids, attention_mask=torch.ones_like(input_ids))\n",
    "        \n",
    "        if storage_key in activation_storage and activation_storage[storage_key]:\n",
    "            hint_activations.append(activation_storage[storage_key][0])\n",
    "        \n",
    "        handle.remove()\n",
    "    \n",
    "    clear_all_hooks()\n",
    "    \n",
    "    if not baseline_activations or not hint_activations:\n",
    "        raise ValueError(\"No activations collected\")\n",
    "    \n",
    "    # Average and compute difference\n",
    "    baseline_avg = torch.stack(baseline_activations).mean(dim=0).squeeze(0)\n",
    "    hint_avg = torch.stack(hint_activations).mean(dim=0).squeeze(0)\n",
    "    steering_vector = hint_avg - baseline_avg\n",
    "    \n",
    "    metadata = {\n",
    "        \"location_type\": location_type,\n",
    "        \"layer_idx\": layer_idx,\n",
    "        \"head_idx\": head_idx,\n",
    "        \"vector_shape\": list(steering_vector.shape),\n",
    "        \"vector_norm\": float(steering_vector.norm().item()),\n",
    "        \"n_problems\": len(target_problems),\n",
    "    }\n",
    "    \n",
    "    return steering_vector, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store and Retrieve Steering Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_l2(vec: torch.Tensor, eps: float = 1e-8):\n",
    "    \"\"\"\n",
    "    L2-normalize a vector.\n",
    "    Preserves direction, fixes scale.\n",
    "    \"\"\"\n",
    "    return vec / (vec.norm(p=2) + eps)\n",
    "\n",
    "def save_steering_vector(steering_vector, metadata, filename=None):\n",
    "    \"\"\"Save steering vector to disk\"\"\"\n",
    "    steering_vector = normalize_l2(steering_vector)\n",
    "    \n",
    "    if filename is None:\n",
    "        loc_str = f\"L{metadata['layer_idx']}\"\n",
    "        if metadata.get('head_idx') is not None:\n",
    "            loc_str += f\"H{metadata['head_idx']}\"\n",
    "        filename = f\"{metadata['location_type']}_{loc_str}.json\"\n",
    "    \n",
    "    # Create subdirectory for this location type if it doesn't exist\n",
    "    subdir = STEERING_VECTORS_DIR / metadata['location_type']\n",
    "    subdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    filepath = subdir / filename\n",
    "    \n",
    "    data = {\n",
    "        \"vector\": steering_vector.cpu().tolist(),\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "    \n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved steering vector to {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def load_steering_vector(filename):\n",
    "    \"\"\"Load steering vector from disk\"\"\"\n",
    "    filepath = STEERING_VECTORS_DIR / filename\n",
    "    \n",
    "    with open(filepath, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    vector = torch.tensor(data[\"vector\"])\n",
    "    metadata = data[\"metadata\"]\n",
    "    \n",
    "    return vector, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Steering and Measure Performance\n",
    "\n",
    "**Note:** The `alpha` parameter scales the steering vector strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def measure_steering_performance(\n",
    "    steering_vector,\n",
    "    location_type,\n",
    "    layer_idx,\n",
    "    head_idx=None,\n",
    "    alpha=1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply steering vector (scaled by alpha) and measure performance.\n",
    "    \n",
    "    Args:\n",
    "        steering_vector: Vector to apply\n",
    "        location_type: \"residual\", \"mlp\", \"attention\", \"o_proj_head\", \"q_head\", \"q_layer\"\n",
    "        layer_idx: Layer index\n",
    "        head_idx: Head index (for o_proj_head and q_head)\n",
    "        alpha: Steering strength multiplier (default 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        results: List of dicts with performance metrics\n",
    "    \"\"\"\n",
    "    if location_type in [\"o_proj_head\", \"q_head\"] and head_idx is None:\n",
    "        raise ValueError(f\"head_idx required for {location_type}\")\n",
    "    \n",
    "    scaled_vector = steering_vector * alpha\n",
    "    results = []\n",
    "    \n",
    "    for tp in tqdm(target_problems, desc=f\"Measuring steering (α={alpha:.2f})\"):\n",
    "        \n",
    "        baseline_prompt_ids = tok.encode(tp[\"baseline_prompt\"], add_special_tokens=False)\n",
    "        hint_prompt_ids = tok.encode(tp[\"hint_prompt\"], add_special_tokens=False)\n",
    "        \n",
    "        # Compute without steering\n",
    "        clear_all_hooks()\n",
    "        baseline_result = compute_answer_logprobs_from_tokens(baseline_prompt_ids, tp[\"correct_answer\"], None)\n",
    "        hint_result = compute_answer_logprobs_from_tokens(hint_prompt_ids, tp[\"correct_answer\"], tp[\"hint_value\"])\n",
    "        \n",
    "        # Compute with steering\n",
    "        clear_all_hooks()\n",
    "        baseline_readout_pos = compute_readout_pos(tp[\"baseline_prompt\"])\n",
    "        handle = setup_steering_hook(location_type, layer_idx, head_idx, baseline_readout_pos, scaled_vector)\n",
    "        baseline_steered_result = compute_answer_logprobs_from_tokens(baseline_prompt_ids, tp[\"correct_answer\"], None)\n",
    "        handle.remove()\n",
    "        \n",
    "        # Compute with steering on hint\n",
    "        clear_all_hooks()\n",
    "        hint_readout_pos = compute_readout_pos(tp[\"hint_prompt\"])\n",
    "        handle = setup_steering_hook(location_type, layer_idx, head_idx, hint_readout_pos, scaled_vector)\n",
    "        hint_steered_result = compute_answer_logprobs_from_tokens(hint_prompt_ids, tp[\"correct_answer\"], tp[\"hint_value\"])\n",
    "        handle.remove()\n",
    "        \n",
    "        results.append({\n",
    "            \"problem_idx\": tp[\"problem_idx\"],\n",
    "            \"variant_idx\": tp[\"variant_idx\"],\n",
    "            \"delta_baseline\": baseline_result[\"delta\"],\n",
    "            \"delta_baseline_steered\": baseline_steered_result[\"delta\"],\n",
    "            \"delta_hint\": hint_result[\"delta\"],\n",
    "            \"delta_hint_steered\": hint_steered_result[\"delta\"],\n",
    "            \"alpha\": alpha,\n",
    "        })\n",
    "    \n",
    "    clear_all_hooks()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_unit_vector(dim, norm=None, device=\"cpu\"):\n",
    "    \"\"\"Generate random unit vector, optionally scaled to match given norm\"\"\"\n",
    "    vec = torch.randn(dim, device=device)\n",
    "    vec = vec / vec.norm()\n",
    "    if norm is not None:\n",
    "        vec = vec * norm\n",
    "    return vec\n",
    "\n",
    "def compare_steering_vs_random(\n",
    "    steering_vector,\n",
    "    location_type,\n",
    "    layer_idx,\n",
    "    head_idx=None,\n",
    "    alpha=1.0\n",
    "):\n",
    "    \"\"\"Compare computed steering vector vs random vector with same norm\"\"\"\n",
    "    print(\"Measuring with computed steering vector...\")\n",
    "    steering_results = measure_steering_performance(\n",
    "        steering_vector, location_type, layer_idx, head_idx=head_idx, alpha=alpha\n",
    "    )\n",
    "    \n",
    "    # Generate random vector with same norm\n",
    "    random_vector = generate_random_unit_vector(\n",
    "        steering_vector.shape[0],\n",
    "        norm=steering_vector.norm().item(),\n",
    "        device=steering_vector.device\n",
    "    )\n",
    "    \n",
    "    print(\"Measuring with random vector (same norm)...\")\n",
    "    random_results = measure_steering_performance(\n",
    "        random_vector, location_type, layer_idx, head_idx=head_idx, alpha=alpha\n",
    "    )\n",
    "    \n",
    "    return steering_results, random_results\n",
    "\n",
    "def apply_vector_at_different_locations(\n",
    "    steering_vector,\n",
    "    source_location_type,\n",
    "    target_layers,\n",
    "    head_idx=None,\n",
    "    alpha=1.0\n",
    "):\n",
    "    \"\"\"Apply same steering vector at different layers\"\"\"\n",
    "    results_dict = {}\n",
    "    \n",
    "    for target_layer_idx in target_layers:\n",
    "        if 0 <= target_layer_idx < NUM_LAYERS:\n",
    "            print(f\"Measuring at L{target_layer_idx}...\")\n",
    "            try:\n",
    "                results = measure_steering_performance(\n",
    "                    steering_vector, source_location_type, target_layer_idx,\n",
    "                    head_idx=head_idx, alpha=alpha\n",
    "                )\n",
    "                results_dict[target_layer_idx] = results\n",
    "            except Exception as e:\n",
    "                print(f\"  Error at L{target_layer_idx}: {e}\")\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_effects(results):\n",
    "    \"\"\"Compute effect sizes from results\"\"\"\n",
    "    for r in results:\n",
    "        r[\"E_hint\"] = r[\"delta_hint\"] - r[\"delta_baseline\"]\n",
    "        r[\"E_steering_baseline\"] = r[\"delta_baseline_steered\"] - r[\"delta_baseline\"]\n",
    "        r[\"E_steering_hint\"] = r[\"delta_hint_steered\"] - r[\"delta_hint\"]\n",
    "        r[\"E_combined\"] = r[\"delta_hint_steered\"] - r[\"delta_baseline\"]\n",
    "        r[\"DD\"] = (r[\"delta_hint_steered\"] - r[\"delta_baseline_steered\"]) - (r[\"delta_hint\"] - r[\"delta_baseline\"])\n",
    "    return results\n",
    "\n",
    "def print_summary(results, name=\"Results\"):\n",
    "    \"\"\"Print summary statistics\"\"\"\n",
    "    results = compute_effects(results)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Mean Δ_baseline: {np.mean([r['delta_baseline'] for r in results]):.3f}\")\n",
    "    print(f\"Mean Δ_baseline_steered: {np.mean([r['delta_baseline_steered'] for r in results]):.3f}\")\n",
    "    print(f\"Mean Δ_hint: {np.mean([r['delta_hint'] for r in results]):.3f}\")\n",
    "    print(f\"Mean Δ_hint_steered: {np.mean([r['delta_hint_steered'] for r in results]):.3f}\")\n",
    "    print(f\"Mean E_hint: {np.mean([r['E_hint'] for r in results]):.3f}\")\n",
    "    print(f\"Mean E_steering_baseline: {np.mean([r['E_steering_baseline'] for r in results]):.3f}\")\n",
    "    print(f\"Mean E_steering_hint: {np.mean([r['E_steering_hint'] for r in results]):.3f}\")\n",
    "    print(f\"Mean DD: {np.mean([r['DD'] for r in results]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_q_layer_indices = [0, 20, 21]\n",
    "top_o_proj_layer_indices = [0, 20, 21]\n",
    "mlp_layer_indices = [1,8,9,11,27]\n",
    "resid_layers = [0,1,8,9,10,11,12,20,21,22,27, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L2): 100%|██████████| 633/633 [00:53<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 0.213\n",
      "Saved steering vector to steering_vectors/residual/residual_L2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L3): 100%|██████████| 633/633 [00:54<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 0.311\n",
      "Saved steering vector to steering_vectors/residual/residual_L3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L4): 100%|██████████| 633/633 [00:57<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 0.543\n",
      "Saved steering vector to steering_vectors/residual/residual_L4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L5): 100%|██████████| 633/633 [00:54<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 0.625\n",
      "Saved steering vector to steering_vectors/residual/residual_L5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L6): 100%|██████████| 633/633 [00:53<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 0.707\n",
      "Saved steering vector to steering_vectors/residual/residual_L6.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L7): 100%|██████████| 633/633 [00:55<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 0.984\n",
      "Saved steering vector to steering_vectors/residual/residual_L7.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L13): 100%|██████████| 633/633 [00:56<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 2.500\n",
      "Saved steering vector to steering_vectors/residual/residual_L13.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L14): 100%|██████████| 633/633 [00:54<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 3.781\n",
      "Saved steering vector to steering_vectors/residual/residual_L14.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L15): 100%|██████████| 633/633 [00:53<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 3.750\n",
      "Saved steering vector to steering_vectors/residual/residual_L15.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L16): 100%|██████████| 633/633 [00:52<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 4.125\n",
      "Saved steering vector to steering_vectors/residual/residual_L16.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L17): 100%|██████████| 633/633 [00:51<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 5.062\n",
      "Saved steering vector to steering_vectors/residual/residual_L17.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L18): 100%|██████████| 633/633 [00:51<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 6.719\n",
      "Saved steering vector to steering_vectors/residual/residual_L18.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L19): 100%|██████████| 633/633 [00:52<00:00, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 8.500\n",
      "Saved steering vector to steering_vectors/residual/residual_L19.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L23): 100%|██████████| 633/633 [00:51<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 25.500\n",
      "Saved steering vector to steering_vectors/residual/residual_L23.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L24): 100%|██████████| 633/633 [00:53<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 28.125\n",
      "Saved steering vector to steering_vectors/residual/residual_L24.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L25): 100%|██████████| 633/633 [00:52<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 36.750\n",
      "Saved steering vector to steering_vectors/residual/residual_L25.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing steering vector (residual L26): 100%|██████████| 633/633 [00:52<00:00, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norm: 41.000\n",
      "Saved steering vector to steering_vectors/residual/residual_L26.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for l in list(range(29)):\n",
    "    if l in resid_layers:\n",
    "        continue\n",
    "    # Compute steering vector for entire Q projection\n",
    "    steering_vec, metadata = compute_steering_vector(\n",
    "        location_type=\"residual\",\n",
    "        layer_idx=l,\n",
    "        head_idx=None\n",
    "    )\n",
    "    print(f\"Vector norm: {metadata['vector_norm']:.3f}\")\n",
    "    \n",
    "    # Save it\n",
    "    save_steering_vector(steering_vec, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_attention, _ = load_steering_vector(\"attention_L20.json\")\n",
    "vec_mlp, _ = load_steering_vector(\"mlp_L20.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=-1.00): 100%|██████████| 633/633 [02:46<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=-1.0) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.362\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.984\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: -0.002\n",
      "Mean E_steering_hint: 0.000\n",
      "Mean DD: 0.002\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=-1.00): 100%|██████████| 633/633 [02:47<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=-1.0) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.373\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.982\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: -0.013\n",
      "Mean E_steering_hint: -0.001\n",
      "Mean DD: 0.012\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=-0.75): 100%|██████████| 633/633 [02:50<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=-0.75) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.359\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.980\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.002\n",
      "Mean E_steering_hint: -0.003\n",
      "Mean DD: -0.005\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=-0.75): 100%|██████████| 633/633 [02:54<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=-0.75) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.345\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.980\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.015\n",
      "Mean E_steering_hint: -0.003\n",
      "Mean DD: -0.018\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=-0.50): 100%|██████████| 633/633 [02:55<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=-0.5) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.365\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.980\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: -0.005\n",
      "Mean E_steering_hint: -0.004\n",
      "Mean DD: 0.002\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=-0.50): 100%|██████████| 633/633 [02:52<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=-0.5) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.355\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.982\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.005\n",
      "Mean E_steering_hint: -0.001\n",
      "Mean DD: -0.007\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=-0.25): 100%|██████████| 633/633 [02:51<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=-0.25) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.357\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.983\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.003\n",
      "Mean E_steering_hint: -0.001\n",
      "Mean DD: -0.004\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=-0.25): 100%|██████████| 633/633 [02:54<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=-0.25) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.358\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.982\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.002\n",
      "Mean E_steering_hint: -0.001\n",
      "Mean DD: -0.003\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=0.25): 100%|██████████| 633/633 [02:53<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=0.25) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.370\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.979\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: -0.010\n",
      "Mean E_steering_hint: -0.004\n",
      "Mean DD: 0.006\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=0.25): 100%|██████████| 633/633 [02:54<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=0.25) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.352\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.980\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.008\n",
      "Mean E_steering_hint: -0.003\n",
      "Mean DD: -0.011\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=0.50): 100%|██████████| 633/633 [02:54<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=0.5) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.357\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.975\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.004\n",
      "Mean E_steering_hint: -0.008\n",
      "Mean DD: -0.012\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=0.50): 100%|██████████| 633/633 [02:55<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=0.5) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.356\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.979\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.004\n",
      "Mean E_steering_hint: -0.004\n",
      "Mean DD: -0.009\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=0.75): 100%|██████████| 633/633 [02:52<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=0.75) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.359\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.980\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.001\n",
      "Mean E_steering_hint: -0.004\n",
      "Mean DD: -0.005\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=0.75): 100%|██████████| 633/633 [02:51<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=0.75) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.362\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.979\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: -0.002\n",
      "Mean E_steering_hint: -0.004\n",
      "Mean DD: -0.002\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=1.00): 100%|██████████| 633/633 [02:51<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=1.0) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.358\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.987\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: 0.002\n",
      "Mean E_steering_hint: 0.004\n",
      "Mean DD: 0.002\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring steering (α=1.00): 100%|██████████| 633/633 [02:54<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steering (α=1.0) ===\n",
      "Mean Δ_baseline: -1.360\n",
      "Mean Δ_baseline_steered: -1.370\n",
      "Mean Δ_hint: 3.983\n",
      "Mean Δ_hint_steered: 3.983\n",
      "Mean E_hint: 5.343\n",
      "Mean E_steering_baseline: -0.010\n",
      "Mean E_steering_hint: -0.001\n",
      "Mean DD: 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Measure performance with alpha scaling\n",
    "print(\"=====================================\")\n",
    "for alpha in [-1.0, -0.75, -0.5, -0.25, 0.25, 0.5, 0.75, 1.0]:\n",
    "    print(\"=====================================\")\n",
    "    results = measure_steering_performance(\n",
    "        vec_attention,\n",
    "        location_type=\"attention\",\n",
    "        layer_idx=TARGET_LAYER,\n",
    "        head_idx=TARGET_HEAD,\n",
    "        alpha=ALPHA\n",
    "    )\n",
    "    print_summary(results, f\"Steering (α={ALPHA})\")\n",
    "\n",
    "    print(\"=====================================\")\n",
    "    results = measure_steering_performance(\n",
    "        vec_mlp,\n",
    "        location_type=\"mlp\",\n",
    "        layer_idx=TARGET_LAYER,\n",
    "        head_idx=TARGET_HEAD,\n",
    "        alpha=alpha\n",
    "    )\n",
    "    print_summary(results, f\"Steering (α={ALPHA})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ablation_summaries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_ablation \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mablation_summaries\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Quick summary table\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_ablation[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_DD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_baseline_damage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_E_hint\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_string())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ablation_summaries' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_ablation = pd.DataFrame(ablation_summaries)\n",
    "\n",
    "# Quick summary table\n",
    "print(df_ablation[[\"location_type\", \"layer_idx\", \"mean_DD\", \"mean_baseline_damage\", \"mean_E_hint\"]].to_string())\n",
    "\n",
    "# Bar plot of DD by location/layer\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "labels = [f\"{row['location_type']}\\nL{int(row['layer_idx'])}\" for _, row in df_ablation.iterrows()]\n",
    "colors = ['coral' if row['mean_DD'] > 0 else 'steelblue' for _, row in df_ablation.iterrows()]\n",
    "ax.bar(range(len(df_ablation)), df_ablation[\"mean_DD\"], color=colors, alpha=0.7)\n",
    "ax.set_xticks(range(len(df_ablation)))\n",
    "ax.set_xticklabels(labels, rotation=45, ha=\"right\", fontsize=8)\n",
    "ax.axhline(y=0, color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "ax.set_ylabel(\"DD (hint-specific effect)\")\n",
    "ax.set_title(\"Ablation: DD by Location/Layer\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure performance with alpha scaling\n",
    "results = measure_steering_performance(\n",
    "    steering_vec,\n",
    "    location_type=\"attention\",\n",
    "    layer_idx=TARGET_LAYER,\n",
    "    head_idx=TARGET_HEAD,\n",
    "    alpha=ALPHA\n",
    ")\n",
    "print_summary(results, f\"Steering (α={ALPHA})\")\n",
    "\n",
    "# Control 1: Compare with random vector\n",
    "steering_results, random_results = compare_steering_vs_random(\n",
    "    steering_vec,\n",
    "    location_type=\"o_proj_head\",\n",
    "    layer_idx=TARGET_LAYER,\n",
    "    head_idx=TARGET_HEAD,\n",
    "    alpha=ALPHA\n",
    ")\n",
    "print_summary(steering_results, \"Computed Steering\")\n",
    "print_summary(random_results, \"Random Vector\")\n",
    "\n",
    "# Control 2: Apply at different layers\n",
    "other_layers = [TARGET_LAYER - 2, TARGET_LAYER, TARGET_LAYER + 2]\n",
    "results_by_layer = apply_vector_at_different_locations(\n",
    "    steering_vec,\n",
    "    source_location_type=\"o_proj_head\",\n",
    "    target_layers=other_layers,\n",
    "    head_idx=TARGET_HEAD,\n",
    "    alpha=ALPHA\n",
    ")\n",
    "for layer_idx, results in results_by_layer.items():\n",
    "    print_summary(results, f\"Layer {layer_idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
